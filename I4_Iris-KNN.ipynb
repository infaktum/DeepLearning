{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Iris 4: Iris-Dataset - Das Neuronale Netz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Beim Iris-Datensatz haben wir gesehen, dass die zusammengehörenden Datensätze im vierdimensionalen Raum nahe beieinanderliegen, also __Cluster__ bilden. Durch einfaches Betrachten verschiedener Darstellungen der Daten konnten wir diese Cluster leicht trennen. Der \"natürliche\" Ansatz, dies zu autimatisieren, war die Methode des __k-means__: Wir suchten k = 3 verscheidenen Mittelwerte, um die sich diese Cluster bilden.\n",
    "\n",
    "Obwohl das Problem dadruch hinreichend gut gelöst ist, wollen wir nun versuchen, das Problem mit einem einfachen neuronalen netzwerk zu lösen. Diese Lösung ist zwar schon fast überdimensioniert, aber da das Problem noch übersichtlich ist, können wir die Wirkungsweise neuronaler Netzwerke hier gut erkennen, bisvor wir zu größeren Problemen (was Daten-Dimension und -Volumen anbetrifft) übergehen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import ki_kurs.iris as ir\n",
    "import pprint as pp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Schritt: Erstellung von Trainings- und Testdaten aus der Iris-Datenbank\n",
    "\n",
    "Wir lesen zunächst die Daten aus der Iris-Datenbank ein und teilen diese dann in eine Menge von Trainingsdaten auf, mit denen das Netzwerk trainiert wird, und eine Menge von Testdaten, mit denen wir dann das Ergebnis überprüfen.\n",
    "\n",
    "Da wir eine Art generisches KNN definieren wollen, skalieren wir die Werte unserer Iris-DB auf den Bereich $[0,1]$. Dies haben wir in der Funktion _tt_daten_ bereits erledigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "iris = ir.IrisDataSet(\"daten/iris.csv\")\n",
    "trainings_daten, test_daten = iris.tt_daten(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Schritt 2: Programmierung eines dreischichtigen Netzwerks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in -> hidden:[[-1.15820901  0.28184704 -0.00437989  0.93494344]\n",
      " [-0.18245714 -0.19688548 -0.36653645 -0.35199413]\n",
      " [-0.42456639  0.25163086  0.59019598  0.03031534]]\n",
      "hidden -> out[[ 0.50583336 -0.84647608 -0.05806003]\n",
      " [ 0.23148974  0.46721303  0.60646773]\n",
      " [ 0.11700412 -0.42180946 -0.34364073]]\n"
     ]
    }
   ],
   "source": [
    "# Ein generisches Neuronales Netzwerk mit einer Eingabeschicht, einer versteckten Schicht und einer Ausgabeschicht.\n",
    "    \n",
    "class NeuralNetwork:\n",
    "    def __init__(self, *nodes: list[int]) -> None:\n",
    "        ''' Setzen der Parameter des Neuronalen Netzwerks. Gewichte werden zufällig erzeugt. '''\n",
    "        self.inodes, self.hnodes, self.onodes = nodes\n",
    "\n",
    "        self.wih = np.random.normal(0.0, pow(self.hnodes, -0.5), (self.hnodes, self.inodes))\n",
    "        self.who = np.random.normal(0.0, pow(self.onodes, -0.5), (self.onodes, self.hnodes))\n",
    "\n",
    "        self.transfer = lambda x: 1/(1 + np.exp(-x)) # Die Sigmoid-Funktion\n",
    "        pass\n",
    "\n",
    "    def train(self, inputs_list: np.ndarray, targets_list: np.ndarray,lr: float = 0.2) -> None :\n",
    "        ''' Training des Neuronalen Netzwerks '''\n",
    "   \n",
    "        inputs =  np.transpose(np.array(inputs_list, ndmin=2))\n",
    "        targets = np.transpose(np.array(targets_list, ndmin=2))\n",
    "\n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "        hidden_outputs = self.transfer(hidden_inputs)\n",
    "\n",
    "        final_inputs = np.dot(self.who, hidden_outputs)\n",
    "        final_outputs = self.transfer(final_inputs)\n",
    "\n",
    "        output_errors = targets - final_outputs\n",
    "        hidden_errors = np.dot(self.who.T, output_errors)\n",
    "        \n",
    "        # Backpropagation\n",
    "        self.who += lr * np.dot((output_errors * final_outputs * (1.0 - final_outputs)), np.transpose(hidden_outputs))\n",
    "        self.wih += lr * np.dot((hidden_errors * hidden_outputs * (1.0 - hidden_outputs)), np.transpose(inputs))\n",
    "    \n",
    "        pass\n",
    "\n",
    "    def query(self, inputs_list: np.ndarray):\n",
    "        ''' Abfrage des Neuronalen Netzwerks '''\n",
    "        inputs = np.array(inputs_list, ndmin=2).T\n",
    "        hidden_inputs = np.dot(self.wih, inputs)\n",
    "        hidden_outputs = self.transfer(hidden_inputs)\n",
    "        final_inputs = np.dot(self.who, hidden_outputs)\n",
    "        final_outputs = self.transfer(final_inputs)\n",
    "        return np.concatenate(final_outputs).ravel()\n",
    "\n",
    "    def result(self, inputs: np.ndarray) -> int:\n",
    "        return np.argmax(self.query(inputs))\n",
    "\n",
    "    def save(self,file: str) -> None:\n",
    "        '''Speichert die Gewichte des Netzwerks'''\n",
    "        with open(file + '.npy', 'wb') as f:\n",
    "            np.save(f,self.wih, allow_pickle=True)\n",
    "            np.save(f,self.who, allow_pickle=True)\n",
    "        print(\"Gewichte wurden gespeichert\")            \n",
    "\n",
    "    def load(self,file: str) -> None:\n",
    "        '''Lädt die Gewichte des Netzwerks'''        \n",
    "        with open(file + '.npy', 'rb') as f:\n",
    "            self.wih = np.load(f)\n",
    "            self.who = np.load(f)\n",
    "        print(\"Gewichte wurden geladen\")      \n",
    "        \n",
    "    def __str__(self) -> str:\n",
    "        return \"in -> hidden:\" + np.array2string(self.wih) +\"\\nhidden -> out\" + np.array2string(self.who)    \n",
    "\n",
    "input_nodes = 4  # Vier verschiedene gemessenene Werte\n",
    "hidden_nodes = 3\n",
    "output_nodes = 3 # Drei Iris-Arten\n",
    "\n",
    "knn = NeuralNetwork(input_nodes,hidden_nodes,output_nodes)\n",
    "print(knn)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Aufbau des Neuronalen Netzes\n",
    "Unser künstliches neuronales Netz hat drei Schichten. Die Anzahl der ein- und Ausgabeknoten ist durch das Problem bestimmt: Wir haben vier Eingabewrte (Breite und Länge der zwei verschiedenen Blätter), und drei verschiedenen Iris-Arten. Bei der Anzahl der Knoten der mittleren Schicht sind wir frei. Hier mehr Knoten als in der Eingabeschicht zu verwenden, oder weniger Knoten als in der Ausgabeschicht, macht wenig Sinn. Im ersten Fall erhalten wir nicht mehr Information, im letzten Fall verlieren wir Information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_nodes = 4  # Vier verschiedene gemessenene Werte\n",
    "hidden_nodes = 3\n",
    "output_nodes = 3 # Drei Iris-Arten\n",
    "\n",
    "knn = NeuralNetwork(input_nodes,hidden_nodes,output_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Trainingsphase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainiere_knn(daten,epochen = 10):\n",
    "    for e in range(epochen):\n",
    "        np.random.shuffle(daten)\n",
    "        for x,y in daten:\n",
    "            inputs = np.asfarray(x)\n",
    "            targets = np.zeros(output_nodes)  # Der Output wird auf 0 gesetzt...\n",
    "            targets[y] = 1.                   #... bis auf das richtige Neuron, das auf 1 gesetzt wird\n",
    "            knn.train(inputs, targets)       \n",
    "            pass\n",
    "        pass\n",
    "\n",
    "trainiere_knn(trainings_daten,1000)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abfrage des Neuronalen Netzwerks\n",
    "Wir können nun unser neuronales Netzwerk abfragen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bestimme_iris(input):\n",
    "    return ir.inv_mapping[knn.result(input[0])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.56410256, 0.41025641, 0.16666667, 0.02564103]), 0] -> Iris-setosa ( 0 )\n"
     ]
    }
   ],
   "source": [
    "rindex = int(len(test_daten) * np.random.random())\n",
    "print(test_daten[rindex] , '->', bestimme_iris(test_daten[rindex]),\"(\",test_daten[rindex][1],\")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test des Neuronalen Netzes anhand der Testdaten\n",
    "\n",
    "Wie gut ist unser neuronales Netz eigentlich wirklich? Dazu zählen wir die Treffer auf der gesamten Menge der Testdaten:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Testergebnis =  94.0 %\n"
     ]
    }
   ],
   "source": [
    "def teste_knn(daten):\n",
    "    tests = []    \n",
    "    for x,y in daten:\n",
    "        tests.append(1 if (knn.result(x) == y) else 0)\n",
    "    return tests\n",
    " \n",
    "tests = teste_knn(test_daten)    \n",
    "print(tests)\n",
    "print (\"Testergebnis = \", np.floor(np.asarray(tests).sum() / len(tests) * 100) , \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wir speichern die Gewichte des Netzwerks zur folgenden Analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gewichte wurden gespeichert\n"
     ]
    }
   ],
   "source": [
    "knn.save(\"Iris\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
